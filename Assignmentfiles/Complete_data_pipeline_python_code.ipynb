{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Project - Data pipelines with Redis**\n",
        "\n",
        "In this project, we have managed to create and design a data pipeline that extracts data from a CSV file, caches it in Redis for faster retrieval, transforms the data to clean, structure, and format it, and finally loads the transformed data into a Postgres database. I have managed to well-organized the code to make it easy to understand, with clear comments explaining each step of the process.\n",
        "\n",
        "The Python code provided defines a data pipeline that extracts data from a CSV file, caches the data in Redis for faster retrieval, transforms the data, and loads it into a Postgres database.\n",
        "\n",
        "The extract_data() function uses pandas to extract the data from the CSV file and caches it in Redis using a Redis client object. The transform_data() function retrieves the data from Redis, cleans, structures and formats it into a new data frame, and returns the transformed data. Finally, the load_data() function connects to the Postgres database, creates a table, and inserts the transformed data into the database.\n",
        "\n",
        "The data_pipeline() function is the main function that orchestrates the data pipeline by calling extract_data(), transform_data(), and load_data() in sequence.\n",
        "\n",
        "This data pipeline can be useful for handling large amounts of data efficiently and reliably by leveraging Redis caching and Postgres for persistent storage."
      ],
      "metadata": {
        "id": "dlCdPPm8Moen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install redis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z1awIpsO-1E",
        "outputId": "d75f8172-e397-411c-f1b7-a98688606bbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.9/dist-packages (4.5.4)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.9/dist-packages (from redis) (4.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraries\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "import redis\n",
        "\n",
        "# Redis Cloud Instance Information\n",
        "redis_host = 'redis-15321.c114.us-east-1-4.ec2.cloud.redislabs.com'\n",
        "redis_port = 15321\n",
        "redis_password = 'kNCwxO32b7hdUiTqekLaZlH3TxkaMFY3'\n",
        "\n",
        "# Postgres Database Information\n",
        "pg_host = '35.237.226.12'\n",
        "pg_database = 'telecommunications_data'\n",
        "pg_port = 5432\n",
        "pg_user = 'postgres'\n",
        "pg_password = 'password'\n",
        "\n",
        "# Redis Client Object\n",
        "redis_client = redis.Redis(host=redis_host, port=redis_port, password=redis_password)\n",
        "\n",
        "# Redis Client Object\n",
        "redis_client = redis.Redis(host=redis_host, port=redis_port, password=redis_password)\n",
        "\n",
        "def extract_data():\n",
        "    \"\"\"\n",
        "    Extract data from CSV file and cache in Redis for faster retrieval\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract data from CSV file using pandas\n",
        "        data = pd.read_csv('customer_call_logs.csv')\n",
        "\n",
        "        # Cache data in Redis for faster retrieval\n",
        "        redis_client.set('customer_call_logs', data.to_json())\n",
        "\n",
        "        print('Data extraction successful.')\n",
        "    \n",
        "    except Exception as e:\n",
        "        print('An error occurred while extracting data:', e)\n",
        "\n",
        "\n",
        "#Let us define the transfrom_data() fucntion\n",
        "def transform_data():\n",
        "    \"\"\"\n",
        "    Retrieve data from Redis cache and transform (clean, structure, format)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Retrieve data from Redis cache\n",
        "        data = pd.read_json(redis_client.get('customer_call_logs').decode('utf-8'))\n",
        "\n",
        "        # Transform data (clean, structure, format)\n",
        "        data['call_cost_usd'] = data['call_cost'].apply(lambda x: float(x[1:]))\n",
        "        data['call_date'] = pd.to_datetime(data['call_date'])\n",
        "        data['call_duration_min'] = data['call_duration'].apply(lambda x: float(x.split(':')[0]) + float(x.split(':')[1])/60)\n",
        "        transformed_data = data[['customer_id', 'call_cost_usd', 'call_destination', 'call_date', 'call_duration_min']]\n",
        "\n",
        "        print('Data transformation successful.')\n",
        "        return transformed_data\n",
        "    \n",
        "    except Exception as e:\n",
        "        print('An error occurred while transforming data:', e)\n",
        "\n",
        "#Let us define the load_data() fucntion\n",
        "def load_data(transformed_data):\n",
        "    \"\"\"\n",
        "    Connect to Postgres database and load transformed data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Connect to Postgres database\n",
        "        conn = psycopg2.connect(host=pg_host, database=pg_database, user=pg_user, password=pg_password)\n",
        "\n",
        "        # Create a cursor object\n",
        "        cur = conn.cursor()\n",
        "\n",
        "        # Create a table to store the data\n",
        "        cur.execute('CREATE TABLE IF NOT EXISTS customer_call_logs (\\\n",
        "                     customer_id INT,\\\n",
        "                     call_cost_usd FLOAT,\\\n",
        "                     call_destination VARCHAR,\\\n",
        "                     call_date TIMESTAMP,\\\n",
        "                     call_duration_min FLOAT\\\n",
        "                     )')\n",
        "\n",
        "        # Insert the transformed data into the database\n",
        "        for i, row in transformed_data.iterrows():\n",
        "            cur.execute(f\"INSERT INTO customer_call_logs (customer_id, call_cost_usd, call_destination, call_date, call_duration_min) VALUES ({row['customer_id']}, {row['call_cost_usd']}, '{row['call_destination']}', '{row['call_date']}', {row['call_duration_min']})\")\n",
        "\n",
        "        # Commit the changes\n",
        "        conn.commit()\n",
        "\n",
        "        # Close the cursor and connection\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "\n",
        "        print('Data loading successful.')\n",
        "    \n",
        "    except Exception as e:\n",
        "        print('An error occurred while loading data:', e)\n",
        "\n",
        "\n",
        "#Defining the main function\n",
        "\n",
        "def data_pipeline():\n",
        "    \"\"\"\n",
        "    Data pipeline function that extracts, transforms, and loads data\n",
        "    \"\"\"\n",
        "    extract_data()\n",
        "    transformed_data = transform_data()\n",
        "    load_data(transformed_data)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Run the data pipeline function\n",
        "    data_pipeline()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVZe-PlcWSTg",
        "outputId": "9b9b1b1d-a1cc-4a15-b54c-c24381501b0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data extraction successful.\n",
            "Data transformation successful.\n",
            "An error occurred while loading data: could not connect to server: Connection timed out\n",
            "\tIs the server running on host \"35.237.226.12\" and accepting\n",
            "\tTCP/IP connections on port 5432?\n",
            "\n"
          ]
        }
      ]
    }
  ]
}